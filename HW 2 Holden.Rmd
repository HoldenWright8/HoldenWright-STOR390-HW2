---
title: "HW 2 Student"
author: "Andy Ackerman"
date: "10/17/2023"
output: 
  html_document:
    number_sections: true
---

This homework is meant to illustrate the methods of classification algorithms as well as their potential pitfalls.  In class, we demonstrated K-Nearest-Neighbors using the `iris` dataset.  Today I will give you a different subset of this same data, and you will train a KNN classifier.  

```{r, echo = FALSE}
set.seed(123)
library(class)

df <- data(iris) 

normal <-function(x) {
  (x -min(x))/(max(x)-min(x))   
}

iris_norm <- as.data.frame(lapply(iris[,c(1,2,3,4)], normal))

subset <- c(1:45, 58, 60:70, 82, 94, 110:150)
iris_train <- iris_norm[subset,] 
iris_test <- iris_norm[-subset,] 

iris_target_category <- iris[subset,5]
iris_test_category <- iris[-subset,5]
```

#
Above, I have given you a training-testing partition.  Train the KNN with $K = 5$ on the training data and use this to classify the 50 test observations.  Once you have classified the test observations, create a contingency table -- like we did in class -- to evaluate which observations your algorithm is misclassifying.   

```{r}
set.seed(123)
#STUDENT INPUT

pr = knn(iris_train,iris_test,cl=iris_target_category,k=5)
iris.knn.table = table(pr,iris_test_category)
iris.knn.table
accuracy = function(x){
  sum(diag(x)/(sum(rowSums(x)))) * 100
}
accuracy(iris.knn.table)
```

#

Discuss your results.  If you have done this correctly, you should have a classification error rate that is roughly 20% higher than what we observed in class.  Why is this the case? In particular run a summary of the `iris_test_category` as well as `iris_target_category` and discuss how this plays a role in your answer.  

*STUDENT INPUT* 

```{r}
summary(iris_test_category)
summary(iris_target_category)
```

The partitioning of the training and testing sets was not done randomly so we do not see a random split of setosa, versicolor, and virginica. The test set has mostly versicolor and the training set has mostly setosa and virginica. Many virgnica were classified as versicolor because the test set has such a high proportion of versicolor. 

Choice of $K$ can also influence this classifier.  Why would choosing $K = 6$ not be advisable for this data? 

*STUDENT INPUT*

Choosing K as 6 would not be advisable for this data because it allows for ties. Another issue is that in the test set there are only 5 setosa observations and it is not advisable to pick a K that is greater than the number of observations of one of the categories. 

#

Build a github repository to store your homework assignments.  Share the link in this file.  

*STUDENT INPUT*

https://github.com/HoldenWright8/HoldenWright-STOR390-HW2
